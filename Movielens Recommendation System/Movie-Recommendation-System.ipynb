{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da49f3b9",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project demonstrates how to build a robust movie recommendation system using the classic MovieLens 1M dataset. The analysis moves beyond a single modeling technique to explore and build a **Content-Based** model, a **Collaborative Filtering** model, and a **Hybrid System** that combines the strengths of both.\n",
    "\n",
    "## The Challenge: Sparsity & The \"Cold Start\" Problem\n",
    "\n",
    "A primary challenge for recommendation engines is data sparsityâ€”most users have rated only a tiny fraction of the available movies. This project explores how different models can overcome this and the related \"cold start\" problem (recommending to new users or items)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e7ddc",
   "metadata": {},
   "source": [
    "### 1. Library Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfa0a69-136d-472f-9e28-aa3cc565d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the 'surprise' library for recommendation systems if not already installed.\n",
    "#pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b937e6b-b5fa-4439-92a3-fd44a0ee77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b4163-69df-47cb-81d2-41395d2ee099",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6d786d-d969-43cc-83aa-69e5cfe13ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Merged DataFrame Head ---\n",
      "   MovieID             Title                       Genres  UserID  Rating  \\\n",
      "0        1  Toy Story (1995)  Animation|Children's|Comedy       1       5   \n",
      "1        1  Toy Story (1995)  Animation|Children's|Comedy       6       4   \n",
      "2        1  Toy Story (1995)  Animation|Children's|Comedy       8       4   \n",
      "3        1  Toy Story (1995)  Animation|Children's|Comedy       9       5   \n",
      "4        1  Toy Story (1995)  Animation|Children's|Comedy      10       5   \n",
      "\n",
      "   Timestamp Gender  Age  Occupation Zip-code  \n",
      "0  978824268      F    1          10    48067  \n",
      "1  978237008      F   50           9    55117  \n",
      "2  978233496      M   25          12    11413  \n",
      "3  978225952      M   25          17    61614  \n",
      "4  978226474      F   35           1    95370  \n"
     ]
    }
   ],
   "source": [
    "# --- Define Column Names ---\n",
    "# Create headers, as the .dat files do not have them.\n",
    "m_cols = ['MovieID', 'Title', 'Genres']\n",
    "r_cols = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "u_cols = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    "\n",
    "# --- Load the Datasets ---\n",
    "# Read the .dat files using '::' as the separator.\n",
    "movies = pd.read_csv('movies.dat', sep='::', names=m_cols, engine='python', encoding='latin-1')\n",
    "ratings = pd.read_csv('ratings.dat', sep='::', names=r_cols, engine='python', encoding='latin-1')\n",
    "users = pd.read_csv('users.dat', sep='::', names=u_cols, engine='python', encoding='latin-1')\n",
    "\n",
    "# --- Merge DataFrames ---\n",
    "# Combine all data into a single DataFrame for easier analysis.\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "df = pd.merge(movie_ratings, users)\n",
    "\n",
    "print(\"--- Merged DataFrame Head ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-markdown-1",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis: The User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62425a81-7c23-4812-9c7d-7df22f33565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- User-Item Matrix (first 5 rows/columns) ---\n",
      "Title   $1,000,000 Duck (1971)  'Night Mother (1986)  \\\n",
      "UserID                                                 \n",
      "1                          NaN                   NaN   \n",
      "2                          NaN                   NaN   \n",
      "3                          NaN                   NaN   \n",
      "4                          NaN                   NaN   \n",
      "5                          NaN                   NaN   \n",
      "\n",
      "Title   'Til There Was You (1997)  'burbs, The (1989)  \\\n",
      "UserID                                                  \n",
      "1                             NaN                 NaN   \n",
      "2                             NaN                 NaN   \n",
      "3                             NaN                 NaN   \n",
      "4                             NaN                 NaN   \n",
      "5                             NaN                 NaN   \n",
      "\n",
      "Title   ...And Justice for All (1979)  \n",
      "UserID                                 \n",
      "1                                 NaN  \n",
      "2                                 NaN  \n",
      "3                                 NaN  \n",
      "4                                 NaN  \n",
      "5                                 NaN  \n",
      "\n",
      "Shape of the User-Item Matrix: (6040, 3706)\n",
      "Sparsity of the matrix: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# --- Create the User-Item Matrix ---\n",
    "# This matrix will have users as rows, movies as columns, and ratings as values.\n",
    "# It is fundamental for our recommendation algorithms.\n",
    "user_item_matrix = df.pivot_table(index='UserID', columns='Title', values='Rating')\n",
    "\n",
    "print(\"\\n--- User-Item Matrix (first 5 rows/columns) ---\")\n",
    "print(user_item_matrix.iloc[:5, :5])\n",
    "\n",
    "# --- Calculate Sparsity ---\n",
    "# Sparsity shows what percentage of the matrix is empty (NaN values).\n",
    "sparsity = 1.0 - (np.count_nonzero(user_item_matrix) / user_item_matrix.size)\n",
    "print(f\"\\nShape of the User-Item Matrix: {user_item_matrix.shape}\")\n",
    "print(f\"Sparsity of the matrix: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "content-based-markdown",
   "metadata": {},
   "source": [
    "### 4. Model 1: Content-Based Filtering\n",
    "\n",
    "This model recommends movies based on their features (genres). The logic is simple: if a user likes a movie, recommend other movies with similar genres. This approach is excellent for solving the \"cold start\" problem for new movies that don't have ratings yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "652bfcf3-17bf-40f1-9aeb-cba39e53cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cosine Similarity Matrix Shape ---\n",
      "(3883, 3883)\n"
     ]
    }
   ],
   "source": [
    "# --- Create TF-IDF (Term Frequency-Inverse Document Frequency) Matrix ---\n",
    "# Convert the text-based genres into a matrix of numbers.\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Replace any NaN values in the 'Genres' column with an empty string.\n",
    "movies['Genres'] = movies['Genres'].fillna('')\n",
    "\n",
    "# Create the TF-IDF matrix by fitting and transforming the 'Genres' data.\n",
    "tfidf_matrix = tfidf.fit_transform(movies['Genres'])\n",
    "\n",
    "# --- Calculate Cosine Similarity ---\n",
    "# Calculate the similarity score between every pair of movies based on their genres.\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "print(\"--- Cosine Similarity Matrix Shape ---\")\n",
    "print(cosine_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e2d943-365d-419f-ae47-ac3c148e979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from movie titles to their index in the dataframe.\n",
    "indices = pd.Series(movies.index, index=movies['Title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf26b377-2c02-44d2-8faa-7b9fe9c9753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the content-based recommendation function.\n",
    "def get_content_based_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title.\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie.\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores.\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies (excluding the movie itself).\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices.\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies.\n",
    "    return movies['Title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8c256d-455a-4b3a-8ce2-62b0a43c26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recommendations For 'Toy Story (1995)' ---\n",
      "1050            Aladdin and the King of Thieves (1996)\n",
      "2072                          American Tail, An (1986)\n",
      "2073        American Tail: Fievel Goes West, An (1991)\n",
      "2285                         Rugrats Movie, The (1998)\n",
      "2286                              Bug's Life, A (1998)\n",
      "3045                                Toy Story 2 (1999)\n",
      "3542                             Saludos Amigos (1943)\n",
      "3682                                Chicken Run (2000)\n",
      "3685    Adventures of Rocky and Bullwinkle, The (2000)\n",
      "12                                        Balto (1995)\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Get a Recommendation Example ---\n",
    "# Test the function with a classic movie.\n",
    "print(\"\\n--- Recommendations For 'Toy Story (1995)' ---\")\n",
    "print(get_content_based_recommendations('Toy Story (1995)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffefd93-c2eb-4ef3-b4f5-9d0ca8d33e10",
   "metadata": {},
   "source": [
    "### 5. Model 2: Collaborative Filtering with SVD\n",
    "\n",
    "This model recommends movies based on the principle that people who agreed in the past will agree in the future. It uses the **Singular Value Decomposition (SVD)** algorithm to find latent patterns in user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f93efd4-5426-4479-887b-ce55d295f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Data for Surprise ---\n",
    "# The 'surprise' library requires data in a specific format.\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(ratings[['UserID', 'MovieID', 'Rating']], reader)\n",
    "\n",
    "# --- Train-Test Split ---\n",
    "# Split the data for model training and evaluation.\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ad95697-55f0-4983-a159-dbe936dd26fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVD model...\n",
      "RMSE: 0.8729\n",
      "\n",
      "Model RMSE: 0.8729\n"
     ]
    }
   ],
   "source": [
    "# --- Train the SVD Model ---\n",
    "svd_model = SVD(random_state=42)\n",
    "\n",
    "print(\"Training the SVD model...\")\n",
    "# Train the model on the training set.\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# --- Evaluate the Model ---\n",
    "# Make predictions on the test set.\n",
    "predictions = svd_model.test(testset)\n",
    "\n",
    "# Calculate and print the Root Mean Squared Error (RMSE).\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"\\nModel RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "599ea3de-b574-4c7c-9aed-5683d94ef388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Collaborative Filtering Recommendations for User 1 ---\n",
      "108                                     Braveheart (1995)\n",
      "315                      Shawshank Redemption, The (1994)\n",
      "847                                 Godfather, The (1972)\n",
      "892                                    Rear Window (1954)\n",
      "910         Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "1186                            Lawrence of Arabia (1962)\n",
      "1256                                Cool Hand Luke (1967)\n",
      "1950    Seven Samurai (The Magnificent Seven) (Shichin...\n",
      "2953                                  General, The (1927)\n",
      "3352                                  Animal House (1978)\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the collaborative filtering recommendation function.\n",
    "def get_collaborative_filtering_recommendations(user_id, model=svd_model, n=10):\n",
    "    # Get a list of all movie IDs.\n",
    "    all_movie_ids = ratings['MovieID'].unique()\n",
    "\n",
    "    # Get the list of movies the user has already rated.\n",
    "    rated_movie_ids = ratings[ratings['UserID'] == user_id]['MovieID'].unique()\n",
    "\n",
    "    # Get the list of movies the user has NOT rated.\n",
    "    unrated_movie_ids = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movie_ids]\n",
    "\n",
    "    # Predict the ratings for all unrated movies.\n",
    "    test_set_for_user = [[user_id, movie_id, 4.] for movie_id in unrated_movie_ids]\n",
    "    user_predictions = model.test(test_set_for_user)\n",
    "\n",
    "    # Sort the predictions by the estimated rating.\n",
    "    user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Get the top N recommended movie IDs.\n",
    "    recommended_movie_ids = [pred.iid for pred in user_predictions[:n]]\n",
    "\n",
    "    # Get the titles of recommended movies.\n",
    "    recommended_movies = movies[movies['MovieID'].isin(recommended_movie_ids)]\n",
    "\n",
    "    return recommended_movies['Title']\n",
    "\n",
    "# --- Get Recommendation Example ---\n",
    "print(\"\\n--- Collaborative Filtering Recommendations for User 1 ---\")\n",
    "print(get_collaborative_filtering_recommendations(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304633d9-5467-4f3c-8293-d05e12dc705a",
   "metadata": {},
   "source": [
    "### 6. Model 3: The Hybrid System\n",
    "\n",
    "This final model combines the outputs of the previous two models. It provides recommendations that are both similar in content to what a user likes and aligned with the tastes of similar users, creating a more robust and personalized experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175a3cdc-7be1-4da2-97d1-66e759ce1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hybrid recommendation function.\n",
    "def get_hybrid_recommendations(user_id, movie_title, n=10):\n",
    "    \"\"\"\n",
    "    Generate hybrid recommendations by combining both models.\n",
    "    \"\"\"\n",
    "    # Get recommendations from the content-based model.\n",
    "    content_recs = get_content_based_recommendations(movie_title, cosine_sim)\n",
    "\n",
    "    # Get recommendations from the collaborative filtering model.\n",
    "    collaborative_recs = get_collaborative_filtering_recommendations(user_id, svd_model)\n",
    "\n",
    "    # Combine and rank the recommendations, giving more weight to collaborative results.\n",
    "    content_set = set(content_recs)\n",
    "    collaborative_set = set(collaborative_recs)\n",
    "    hybrid_recs = {}\n",
    "    for movie in content_set:\n",
    "        hybrid_recs[movie] = hybrid_recs.get(movie, 0) + 1.0 # Base score\n",
    "\n",
    "    for movie in collaborative_set:\n",
    "        hybrid_recs[movie] = hybrid_recs.get(movie, 0) + 1.5 # Higher score for taste alignment\n",
    "\n",
    "    # Sort the recommendations by their combined score.\n",
    "    sorted_hybrid_recs = sorted(hybrid_recs.items(), key=lambda x: x[1], reverse=True)\n",
    "    final_recommendations = [rec[0] for rec in sorted_hybrid_recs]\n",
    "\n",
    "    # Return the top N recommendations.\n",
    "    return final_recommendations[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "557e182b-1bf1-45b4-a2ec-6d9eb86594e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 Hybrid Recommendations ---\n",
      "1. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "2. Braveheart (1995)\n",
      "3. Godfather, The (1972)\n",
      "4. Animal House (1978)\n",
      "5. Lawrence of Arabia (1962)\n",
      "6. Cool Hand Luke (1967)\n",
      "7. Rear Window (1954)\n",
      "8. Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "9. Shawshank Redemption, The (1994)\n",
      "10. General, The (1927)\n"
     ]
    }
   ],
   "source": [
    "# --- Get a Hybrid Recommendation Example ---\n",
    "# Recommend movies for User 1 who liked 'Toy Story (1995)'\n",
    "recommendations = get_hybrid_recommendations(user_id=1, movie_title='Toy Story (1995)')\n",
    "print(\"\\n--- Top 10 Hybrid Recommendations ---\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f2fe2-4b8d-4693-aa7a-917f44337fa6",
   "metadata": {},
   "source": [
    "### 7. Final Evaluation - Precision and Recall @ k\n",
    "\n",
    "To finalize the project, evaluate the performance of the core collaborative filtering model. This provides a quantitative measure of how good the recommendation lists are.\n",
    "\n",
    "- **Precision@k:** Out of the top `k` movies recommended, what proportion did the user actually like?\n",
    "- **Recall@k:** Out of all the movies the user liked, what proportion did we successfully recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fbbdfeb-558d-449d-93a6-564b70c31734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to calculate precision and recall at k.\n",
    "def precision_recall_at_k(predictions, k=10, threshold=4.0):\n",
    "    \"\"\"\n",
    "    Return precision and recall at k for each user.\n",
    "    \"\"\"\n",
    "    # Map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value.\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Count number of relevant items.\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Count number of recommended items in top k.\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Count number of relevant and recommended items in top k.\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Calculate Precision@k.\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Calculate Recall@k.\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "268345da-5beb-471b-9ae2-51d023307ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Collaborative Filtering (SVD) Model ---\n",
      "Average Precision@10: 0.8734\n",
      "Average Recall@10: 0.3679\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate our SVD model with the new metrics ---\n",
    "# The 'predictions' variable is from our SVD model's test set.\n",
    "print(\"--- Evaluating Collaborative Filtering (SVD) Model ---\")\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4.0)\n",
    "\n",
    "# Average the scores across all users.\n",
    "avg_precision = sum(p for p in precisions.values()) / len(precisions)\n",
    "avg_recall = sum(r for r in recalls.values()) / len(recalls)\n",
    "\n",
    "print(f\"Average Precision@10: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall@10: {avg_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4440bf",
   "metadata": {},
   "source": [
    "### 8. Project Conclusion\n",
    "\n",
    "This project successfully built and evaluated a recommendation system using multiple techniques. The core collaborative filtering model (SVD) demonstrated strong performance, achieving a **Precision@10 of 87.3%**. This indicates that the model's top-10 recommendations are highly relevant to users.\n",
    "\n",
    "Furthermore, a hybrid system was developed to conceptually combine the strengths of both content-based and collaborative filtering models. This advanced approach provides a robust framework for handling real-world challenges like the \"cold start\" problem and delivering highly personalized recommendations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
