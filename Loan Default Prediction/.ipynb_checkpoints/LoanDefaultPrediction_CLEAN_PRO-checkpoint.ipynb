{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cf2874",
   "metadata": {},
   "source": [
    "# üìä Loan Default Prediction\n",
    "This project presents a professional machine learning pipeline to predict loan default risk using borrower data.\n",
    "\n",
    "**Author:** Reda El Gadida  \n",
    "**Tools:** Python, Pandas, Scikit-learn, Seaborn, Jupyter Notebook\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911643c",
   "metadata": {},
   "source": [
    "## üß≠ Project Overview\n",
    "This notebook demonstrates how to build and evaluate a predictive model for loan default risk. We simulate a real-world scenario where a financial institution wants to automate credit risk assessment.\n",
    "\n",
    "**Steps covered:**\n",
    "- Load and explore the dataset\n",
    "- Clean and preprocess the data\n",
    "- Train a classification model\n",
    "- Evaluate model performance\n",
    "- Provide insights and conclusions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e0f48",
   "metadata": {},
   "source": [
    "![COUR_IPO.png](attachment:COUR_IPO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe73f79",
   "metadata": {},
   "source": [
    "### Understanding the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4f146",
   "metadata": {},
   "source": [
    "#### Train vs. Test\n",
    "In this competition, you‚Äôll gain access to two datasets that are samples of past borrowers of a financial institution that contain information about the individual and the specific loan. One dataset is titled `train.csv` and the other is titled `test.csv`.\n",
    "\n",
    "`train.csv` contains 70% of the overall sample (255,347 borrowers to be exact) and importantly, will reveal whether or not the borrower has defaulted on their loan payments (the ‚Äúground truth‚Äù).\n",
    "\n",
    "The `test.csv` dataset contains the exact same information about the remaining segment of the overall sample (109,435 borrowers to be exact), but does not disclose the ‚Äúground truth‚Äù for each borrower. It‚Äôs your job to predict this outcome!\n",
    "\n",
    "Using the patterns you find in the `train.csv` data, predict whether the borrowers in `test.csv` will default on their loan payments, or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552466c",
   "metadata": {},
   "source": [
    "#### Dataset descriptions\n",
    "Both `train.csv` and `test.csv` contain one row for each unique Loan. For each Loan, a single observation (`LoanID`) is included during which the loan was active. \n",
    "\n",
    "In addition to this identifier column, the `train.csv` dataset also contains the target label for the task, a binary column `Default` which indicates if a borrower has defaulted on payments.\n",
    "\n",
    "Besides that column, both datasets have an identical set of features that can be used to train your model to make predictions. Below you can see descriptions of each feature. Familiarize yourself with them so that you can harness them most effectively for this machine learning task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7cb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "import pandas as pd\n",
    "data_descriptions = pd.read_csv('data_descriptions.csv')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "data_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# Import required packages\n",
    "\n",
    "# Data packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning / Classification packages\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Visualization Packages\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b421d0",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "Let's start by loading the dataset `train.csv` into a dataframe `train_df`, and `test.csv` into a dataframe `test_df` and display the shape of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d332a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "print('train_df Shape:', train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f173cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print('test_df Shape:', test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d501622",
   "metadata": {},
   "source": [
    "### Explore, Clean, Validate, and Visualize the Data (optional)\n",
    "\n",
    "Feel free to explore, clean, validate, and visualize the data however you see fit for this competition to help determine or optimize your predictive model. Please note - the final autograding will only be on the accuracy of the `prediction_df` predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56752699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# your code here (optional)\n",
    "X_train = train_df.drop(columns=['LoanID', 'Default'])\n",
    "y_train = train_df['Default']\n",
    "X_test = test_df.drop(columns='LoanID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e58258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "#encode categorical variables using one hot encoding\n",
    "categorical_cols = X_train.select_dtypes(include = \"object\").columns\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "\n",
    "X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join = \"left\", axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "#validation split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1ff2f",
   "metadata": {},
   "source": [
    "### Make predictions (required)\n",
    "\n",
    "Remember you should create a dataframe named `prediction_df` with exactly 109,435 entries plus a header row attempting to predict the likelihood of borrowers to default on their loans in `test_df`. Your submission will throw an error if you have extra columns (beyond `LoanID` and `predicted_probaility`) or extra rows.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "`LoanID` (sorted in any order)\n",
    "`predicted_probability` (contains your numeric predicted probabilities between 0 and 1, e.g. from `estimator.predict_proba(X, y)[:, 1]`)\n",
    "\n",
    "The naming convention of the dataframe and columns are critical for our autograding, so please make sure to use the exact naming conventions of `prediction_df` with column names `LoanID` and `predicted_probability`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de26dd",
   "metadata": {},
   "source": [
    "#### Example prediction submission:\n",
    "\n",
    "The code below is a very naive prediction method that simply predicts loan defaults using a Dummy Classifier. This is used as just an example showing the submission format required. Please change/alter/delete this code below and create your own improved prediction methods for generating `prediction_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e64bab",
   "metadata": {},
   "source": [
    "**PLEASE CHANGE CODE BELOW TO IMPLEMENT YOUR OWN PREDICTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e288a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train_final)\n",
    "rf_val_proba = rf_model.predict_proba(X_val)[:, 1]\n",
    "rf_auc = roc_auc_score(y_val, rf_val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70874fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_final, y_train_final)\n",
    "gb_val_proba = gb_model.predict_proba(X_val)[:, 1]\n",
    "gb_auc = roc_auc_score(y_val, gb_val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a97b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "#train XGBOOST\n",
    "xgb_model = XGBClassifier(use_label_encode=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train_final, y_train_final)\n",
    "xgb_val_proba = xgb_model.predict_proba(X_val)[:, 1]\n",
    "xgb_auc = roc_auc_score(y_val, xgb_val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# Display AUC scores\n",
    "print(f\"Random Forest AUC: {rf_auc:.4f}\")\n",
    "print(f\"Gradient Boosting AUC: {gb_auc:.4f}\")\n",
    "print(f\"XGBoost AUC: {xgb_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "#Training the final model with GradientBoostingClassifier\n",
    "final_model = GradientBoostingClassifier(random_state=42)\n",
    "final_model.fit(X_train_final, y_train_final)\n",
    "y_test_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "prediction_df =pd.DataFrame({\n",
    "    'LoanID': test_df['LoanID'],\n",
    "    'predicted_probability': y_test_proba\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d55e1f",
   "metadata": {},
   "source": [
    "**PLEASE CHANGE CODE ABOVE TO IMPLEMENT YOUR OWN PREDICTIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bfb1b",
   "metadata": {},
   "source": [
    "### Final Tests - **IMPORTANT** - the cells below must be run prior to submission\n",
    "\n",
    "Below are some tests to ensure your submission is in the correct format for autograding. The autograding process accepts a csv `prediction_submission.csv` which we will generate from our `prediction_df` below. Please run the tests below an ensure no assertion errors are thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc29d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "# Writing to csv for autograding purposes\n",
    "prediction_df.to_csv(\"prediction_submission.csv\", index=False)\n",
    "submission = pd.read_csv(\"prediction_submission.csv\")\n",
    "\n",
    "assert isinstance(submission, pd.DataFrame), 'You should have a dataframe named prediction_df.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2aaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "assert submission.columns[0] == 'LoanID', 'The first column name should be CustomerID.'\n",
    "assert submission.columns[1] == 'predicted_probability', 'The second column name should be predicted_probability.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cac166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "assert submission.shape[0] == 109435, 'The dataframe prediction_df should have 109435 rows.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "assert submission.shape[1] == 2, 'The dataframe prediction_df should have 2 columns.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944af3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code Block ---\n",
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "## This cell calculates the auc score and is hidden. Submit Assignment to see AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf2314",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion\n",
    "We developed a basic machine learning pipeline to predict loan default risk using logistic regression. This approach can be extended with more complex models and feature engineering techniques to improve accuracy. All source code and analysis are fully documented for transparency and reuse.\n",
    "\n",
    "For business use, model monitoring, explainability, and fairness checks should also be included."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
